{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa90d0f1",
   "metadata": {},
   "source": [
    "For this case study, you will perform a classification task on a WiFi dataset. You will use WLAN fingerprints to identify the location of a user. You will identify locations using the building numbers and floor numbers only. \n",
    "\n",
    "You will also explore the question, \"is more data useful for a classification task?\"\n",
    "\n",
    "The dataset you will use can be found on: https://archive.ics.uci.edu/ml/datasets/ujiindoorloc .\n",
    "\n",
    "**\\[Step 1\\]** Once you examine the data sets, you will find that there is a training set and a validation set. However, you must also create a test set that has the same number of samples as the validation set. You can select and remove random samples from the training set and use them to create a test set. The test set should not be used in the training process or to optimize the parameters of any algorithm you use. The test set should only be used to report the final performance of a model whenever necessary.\n",
    "\n",
    "You may need to determine the features and labels of your model. You can also do some engineering on features and labels if necessary.\n",
    "\n",
    "**\\[Step 2\\]** But, which algorithm should you use with your model? You can refer to the scikit-learn cheat sheet: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html, and try three algorithms. Some suggestions are: LinearSVC, Logistic Regression, KNN classifier, SVC, Random Forest (as an example of Ensemble Learning) etc. Perform one experiment using each and observe the performance of each model. Note which is the best performing model using the test set.\n",
    "\n",
    "**\\[Step 3\\]** Once the previous step is done, observe if more data is useful for a classification task. For this, randomly select 20% of the training samples, but keep the size of the test set the same. You wil not use the validation set in this step as you will not optimize the model in any way. Note the performance. Then also try with 40%, 60%, 80% and 100% of the training samples. Perform three experiments for each size of the training set. This means, for 20% you will do three experiments, 40% three experiments etc. Find the average of three experiments for each size and plot them using a method of your choice.\n",
    "\n",
    "**\\[Step 4\\]** Publish your finding in presentation slides. Like case study 1, three of you will be randomly chosen to present your work in front of the class. The slides should inform the audience about:\n",
    "\n",
    "* the objective of the case study\n",
    "* the data (features and labels)\n",
    "* things you have done (e.g. why you selected a specific classification model)\n",
    "* challenges you have faced that might be interesting to your classmates\n",
    "* your findings\n",
    "\n",
    "\n",
    "**Things to note**:\n",
    "\n",
    "* **Type of task**: classification\n",
    "* **Features**: you choose\n",
    "* **Feature engineering**: You are welcome to do so.\n",
    "* **Labels**: User locations. Use building and floor IDs, but ignore the SPACEID column.\n",
    "\n",
    "* In some cases, normalization may result in reduced accuracy.\n",
    "* You must write enough comments so that anybody with some programming knowledge can understand your code.\n",
    "\n",
    "Also,\n",
    "* This is not a group project. But if you think you will benefit from working with a partner, you are welcome to find a partner. In that case, please send an email to the TA and the professor by **September 24, 2024**. Please note that if you choose to work with a partner, it will not impact your score, but you must send the email by September 24. Only one email is enough. Please make sure to CC your partner.\n",
    "\n",
    "**Grading Criteria**:\n",
    "\n",
    "* [15 + 15] Data set preparation: Choosing your $X$ (features) and $y$ (label). Feature Engineering.\n",
    "* [15 + 15 + 15] Three experiments using three algorithms.  \n",
    "* [15] Observing the effects of more data using five sets of random samples of different sizes from the training set. \n",
    "* [10] Presentation slides and presentation.\n",
    "\n",
    "**What to submit**:\n",
    "\n",
    "Put the Jupyter Notebook file and the .csv file in a folder. Then convert your presentation slides to a PDF file and put it in the same folder. Zip the folder. After zipping, it should have the extension .zip. The name of the .zip file should be firstname_lastname_casestudy_2.zip . Upload the .zip file on Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42b2b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start here\n",
    "# create as many cells as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa9b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
